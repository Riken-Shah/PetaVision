# -*- coding: utf-8 -*-
"""FSCS Inference.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DofRHtiGPLz1mIVC2jqa-CrD1yUCviA6

Inference for an image
"""

import os

os.environ["CUDA_VISIBLE_DEVICES"] = "0"

# Commented out IPython magic to ensure Python compatibility.
# !git clone https://github.com/pfnet-research/FSCS.git
# %cd FSCS/src

# from __future__ import print_function
from sklearn.cluster import KMeans
import argparse
import numpy as np
import torch
import torch.utils.data
from torch import nn, optim
from torch.nn import functional as F
from torchvision import datasets, transforms
import torch.backends.cudnn as cudnn
from torchvision.utils import save_image
from net import MaskGenerator, ResiduePredictor
from mydataset import MyDataset
import cv2
import os
import time
import pathlib
### Define Variables
models_dir = pathlib.Path("layering", "models")
test_imgs_dir = pathlib.Path("layering", "runs")
output_dir = pathlib.Path("layering", "runs", "outputs")
processing_dir =  pathlib.Path("layering", "runs")
num_primary_color = 7
resize_scale_factor = 1
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


### Create Dir
def create_dir_if_not_exists(directory_path):
    if not os.path.exists(directory_path):
        # Create the directory if it doesn't exist
        os.makedirs(directory_path)
        print(f"Directory '{directory_path}' created.")
    else:
        print(f"Directory '{directory_path}' already exists.")


create_dir_if_not_exists(test_imgs_dir)
create_dir_if_not_exists(output_dir)
create_dir_if_not_exists(processing_dir)

### Generate Color Pallete
import numpy as np
import cv2


def get_color_pallete(img_path, num_clusters):
    img = cv2.imread(img_path)[:, :, [2, 1, 0]]
    size = img.shape[:2]
    vec_img = img.reshape(-1, 3)
    model = KMeans(n_clusters=num_clusters, )  # n_jobs)
    pred = model.fit_predict(vec_img)
    pred_img = np.tile(pred.reshape(*size, 1), (1, 1, 3))

    center = model.cluster_centers_.reshape(-1)
    return center


# 必要な関数を定義する

def replace_color(primary_color_layers, manual_colors):
    temp_primary_color_layers = primary_color_layers.clone()
    for layer in range(len(manual_colors)):
        for color in range(3):
            temp_primary_color_layers[:, layer, color, :, :].fill_(manual_colors[layer][color])
    return temp_primary_color_layers


def cut_edge(target_img):
    # print(target_img.size())
    target_img = F.interpolate(target_img, scale_factor=resize_scale_factor, mode='area')
    # print(target_img.size())
    h = target_img.size(2)
    w = target_img.size(3)
    h = h - (h % 8)
    w = w - (w % 8)
    target_img = target_img[:, :, :h, :w]
    # print(target_img.size())
    return target_img


def alpha_normalize(alpha_layers):
    # constraint (sum = 1)
    # layersの状態で受け取り，その形で返す. bn, ln, 1, h, w
    return alpha_layers / (alpha_layers.sum(dim=1, keepdim=True) + 1e-8)


# def read_backimage():
#     img = cv2.imread('../dataset/backimage.jpg')
#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
#     img = img.transpose((2,0,1))
#     img = img/255
#     img = torch.from_numpy(img.astype(np.float32))
#
#     return img.view(1,3,256,256).to(device)
#
# backimage = read_backimage()

from guided_filter_pytorch.guided_filter import GuidedFilter


def proc_guidedfilter(alpha_layers, guide_img):
    # guide_imgは， 1chのモノクロに変換
    # target_imgを使う． bn, 3, h, w
    guide_img = (guide_img[:, 0, :, :] * 0.299 + guide_img[:, 1, :, :] * 0.587 + guide_img[:, 2, :,
                                                                                 :] * 0.114).unsqueeze(1)

    # lnのそれぞれに対してguideg filterを実行
    for i in range(alpha_layers.size(1)):
        # layerは，bn, 1, h, w
        layer = alpha_layers[:, i, :, :, :]

        processed_layer = GuidedFilter(3, 1 * 1e-6)(guide_img, layer)
        # レイヤーごとの結果をまとめてlayersの形に戻す (bn, ln, 1, h, w)
        if i == 0:
            processed_alpha_layers = processed_layer.unsqueeze(1)
        else:
            processed_alpha_layers = torch.cat((processed_alpha_layers, processed_layer.unsqueeze(1)), dim=1)

    return processed_alpha_layers


# target_layer_number = [0, 1] # マスクで操作するレイヤーの番号
# # mask_path = '/content/WhatsApp (1).jpeg'


# ## Define functions for mask operation.
# # マスクを受け取る関数
# # target_layer_numberが冗長なレイヤーの番号（２つ）のリスト．これらのレイヤーに操作を加える

# def load_mask(mask_path):
#     mask = cv2.imread(mask_path, 0) #白黒で読み込み
#     mask[mask<128] = 0.
#     mask[mask >= 128] = 1.
#     # tensorに変換する
#     mask = torch.from_numpy(mask).unsqueeze(0).unsqueeze(0).float().cuda()

#     return mask


# def mask_operate(alpha_layers, target_layer_number, mask_path):
#     layer_A = alpha_layers[:, target_layer_number[0], :, :, :]
#     layer_B = alpha_layers[:, target_layer_number[1], :, :, :]

#     layer_AB = layer_A + layer_B
#     mask = load_mask(mask_path)

#     mask = cut_edge(mask)

#     layer_A = layer_AB * mask
#     layer_B = layer_AB * (1. - mask)

#     return_alpha_layers = alpha_layers.clone()
#     return_alpha_layers[:, target_layer_number[0], :, :, :] = layer_A
#     return_alpha_layers[:, target_layer_number[1], :, :, :] = layer_B

#     return return_alpha_layers

# # datasetにある画像のパスを置き換えてしまう
# test_dataset.imgs_path[0] = img_path

# print(img_path)

def generate_layers(run_name, img_name, test_loader, manual_colors):
    print('Start!')
    img_number = 0

    mean_estimation_time = 0
    with torch.no_grad():
        for batch_idx, (target_img, primary_color_layers) in enumerate(test_loader):
            if batch_idx != img_number:
                print('Skip ', batch_idx)
                continue
            print('img #', batch_idx)
            target_img = cut_edge(target_img)
            target_img = target_img.to(device)  # bn, 3ch, h, w
            primary_color_layers = primary_color_layers.to(device)
            # primary_color_layers = color_regresser(target_img)
            ##
            ##
            primary_color_layers = replace_color(primary_color_layers, manual_colors)  # ここ
            ##
            # print(primary_color_layers.mean())
            # print(primary_color_layers.size())
            start_time = time.time()
            primary_color_pack = primary_color_layers.view(primary_color_layers.size(0), -1,
                                                           primary_color_layers.size(3), primary_color_layers.size(4))
            primary_color_pack = cut_edge(primary_color_pack)
            primary_color_layers = primary_color_pack.view(primary_color_pack.size(0), -1, 3,
                                                           primary_color_pack.size(2), primary_color_pack.size(3))
            pred_alpha_layers_pack = mask_generator(target_img, primary_color_pack)
            pred_alpha_layers = pred_alpha_layers_pack.view(target_img.size(0), -1, 1, target_img.size(2),
                                                            target_img.size(3))
            ## Alpha Layer Proccessing
            processed_alpha_layers = alpha_normalize(pred_alpha_layers)
            # processed_alpha_layers = mask_operate(processed_alpha_layers, target_layer_number, mask_path) # Option
            processed_alpha_layers = proc_guidedfilter(processed_alpha_layers, target_img)  # Option
            processed_alpha_layers = alpha_normalize(processed_alpha_layers)  # Option
            ##
            mono_color_layers = torch.cat((primary_color_layers, processed_alpha_layers), 2)  # shape: bn, ln, 4, h, w
            mono_color_layers_pack = mono_color_layers.view(target_img.size(0), -1, target_img.size(2),
                                                            target_img.size(3))
            residue_pack = residue_predictor(target_img, mono_color_layers_pack)
            residue = residue_pack.view(target_img.size(0), -1, 3, target_img.size(2), target_img.size(3))
            pred_unmixed_rgb_layers = torch.clamp((primary_color_layers + residue), min=0., max=1.0)
            reconst_img = (pred_unmixed_rgb_layers * processed_alpha_layers).sum(dim=1)
            end_time = time.time()
            estimation_time = end_time - start_time
            print(estimation_time)
            mean_estimation_time += estimation_time

            if True:
                # batchsizeは１で計算されているはず．それぞれ保存する．
                save_layer_number = 0
                save_image(primary_color_layers[save_layer_number, :, :, :, :],
                           pathlib.Path(processing_dir, "results", run_name, img_name + '_img-%02d_primary_color_layers.png' % batch_idx))
                save_image(reconst_img[save_layer_number, :, :, :].unsqueeze(0),
                           pathlib.Path(processing_dir, "results", run_name,
                                        img_name + '_img-%02d_reconst_img.png' % batch_idx))
                save_image(target_img[save_layer_number, :, :, :].unsqueeze(0),
                           pathlib.Path(processing_dir, "results", run_name,
                                        img_name + '_img-%02d_target_img.png' % batch_idx))

                # RGBAの４chのpngとして保存する
                RGBA_layers = torch.cat((pred_unmixed_rgb_layers, processed_alpha_layers),
                                        dim=2)  # out: bn, ln, 4, h, w
                # test ではバッチサイズが１なので，bn部分をなくす
                RGBA_layers = RGBA_layers[0]  # ln, 4. h, w
                # ln ごとに結果を保存する
                for i in range(len(RGBA_layers)):
                    save_image(RGBA_layers[i, :, :, :],
                               pathlib.Path(processing_dir, "results", run_name,
                                            img_name, "layers", "img-%02d_layer-%02d.png" % (batch_idx,i)))


                print(f'Saved to {processing_dir}/results/%s/%s/...' % (run_name, img_name))

            if False:
                ### mono_colorの分も保存する ###
                # RGBAの４chのpngとして保存する
                mono_RGBA_layers = torch.cat((primary_color_layers, processed_alpha_layers),
                                             dim=2)  # out: bn, ln, 4, h, w
                # test ではバッチサイズが１なので，bn部分をなくす
                mono_RGBA_layers = mono_RGBA_layers[0]  # ln, 4. h, w
                # ln ごとに結果を保存する
                for i in range(len(mono_RGBA_layers)):
                    save_image(mono_RGBA_layers[i, :, :, :],
                               'results/%s/%s/mono_img-%02d_layer-%02d.png' % (run_name, img_name, batch_idx, i))

                save_image(
                    (primary_color_layers * processed_alpha_layers).sum(dim=1)[save_layer_number, :, :, :].unsqueeze(0),
                    'results/%s/%s/test' % (run_name, img_name) + '_mono_img-%02d_reconst_img.png' % batch_idx)

            if batch_idx == 0:
                break  # debug用


def generate_psd(index):
    # !npm install ag-psd canvas image-size

    psd_path = pathlib.Path(processing_dir, "results", "sample", index + ".jpeg", "output.psd")
    outputFolder = pathlib.Path(processing_dir, "results", "sample", index + ".jpeg", "layers")
    js_code = """
  const fs = require('fs');
  const { createCanvas, loadImage } = require('canvas');
  const { initializeCanvas, writePsd, readPsd } = require('ag-psd');
  const { promisify } = require('util');
  const sizeOf = promisify(require('image-size'));""" + f"""const psdFilePath = '{psd_path.as_posix()}';""" + f"""const outputFolder = '{outputFolder.as_posix()}';""" + """
  async function generatePSD() {
    const imageFiles = fs.readdirSync(outputFolder).map(file => `${outputFolder}/${file}`);

    if (imageFiles.length === 0) {
      console.error('No images found in the folder.');
      return;
    }

    // Get dimensions from the first image
    const { width, height } = await sizeOf(imageFiles[0]);

    // Initialize the main canvas
    const mainImageCanvas = createCanvas(width, height);
    const mainImageContext = mainImageCanvas.getContext('2d');

    // Initialize the PSD children array
    const psdChildren = [];

    let i = 1;
    for (const imagePath of imageFiles) {
      const image = await loadImage(imagePath);

      // Create a canvas with the same dimensions as the image
      const canvas = createCanvas(image.width, image.height);

      // Draw the image onto the canvas
      const ctx = canvas.getContext('2d');
      ctx.drawImage(image, 0, 0);

      // Create a layer for each image and add it to the PSD children
      const layer = {
        name: `layer-${i++}`,
        left: 0, // Adjust as needed
        top: 0, // Adjust as needed
        blendMode: "normal",
        opacity: 1, // Adjust as needed
        mask: null, // Adjust as needed
        type: "layer",
        compressionMethod: 1,
        canvas: canvas,
      };

      psdChildren.push(layer);
    }

    // Create the PSD object
    const psd = {
      width: width,
      height: height,
      channels: 3,
      bitsPerChannel: 8,
      colorMode: 3,
      children: psdChildren,
      canvas: mainImageCanvas,
    };

    // Write the PSD to a file
    // const psdBuffer = writePsd(psd);
  // fs.writeFileSync(psdFilePath, psdBuffer);
      const arrayBuffer = writePsd(psd, { generateThumbnail: false });



  // Write the arrayBuffer to a file
  fs.writeFileSync(psdFilePath, Buffer.from(arrayBuffer));


    console.log(`PSD file generated with dimensions: ${width} x ${height}`);
  }

  generatePSD();
  """

    # Write the JavaScript code to a file
    js_file_path = 'generate_psd.js'
    with open(js_file_path, 'w') as js_file:
        js_file.write(js_code)

    # Execute the JavaScript code using Node.js
    import subprocess

    node_command = f'node {js_file_path}'
    process = subprocess.Popen(node_command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    stdout, stderr = process.communicate()

    # Print the output and error messages
    print("Output:", stdout.decode())
    print("Error:", stderr.decode())
    return psd_path


# Commented out IPython magic to ensure Python compatibility.
import os
import pandas as pd
import math
from PIL import Image

path_mask_generator = pathlib.Path(models_dir, "mask_generator.pth")
path_residue_predictor =  pathlib.Path(models_dir, "residue_predictor.pth")

# define model
mask_generator = None
residue_predictor = None

def perform_layering(test_imgs_dir, img_name, dominant_colors):
    # for img_name in os.listdir(test_imgs_dir):
    #   %cd {processing_dir}
    _, file_extension = os.path.splitext(img_name.lower())
    valid_image_formats = ['.jpg', '.jpeg', '.png', '.gif', '.bmp']  # Add more if needed

    if file_extension in valid_image_formats:
        # Process the image file
        # Your existing code for handling the image file goes here
        print(f"Processing image: {img_name}")
    else:
        print(f"Ignoring non-image file: {img_name}")
        return
        # continue

    file_name = img_name.split(".")[0]

    final_img_name = f"{file_name}.jpeg"
    Image.open(os.path.join(test_imgs_dir, img_name)).convert("RGB").save(os.path.join(processing_dir, final_img_name))
    run_name = "sample"
    original_img_name = os.path.splitext(os.path.basename(img_name))[0]

    # Create CSV File which describes test images path.
    csv_df = pd.DataFrame()
    # csv_df = csv_df.append(pd.Series([f"{processing_dir}/{final_img_name}"]), ignore_index=True)
    csv_df = pd.concat([csv_df, pd.DataFrame([pathlib.Path(processing_dir, final_img_name)])], ignore_index=True)
    csv_path = pathlib.Path(processing_dir, run_name + ".csv")
    pallete_csv_path =  pathlib.Path(processing_dir, run_name + "_pallete.csv")
    csv_df.to_csv(csv_path, index=False, header=False)

    # Create color palettes csv
    # center = get_color_pallete(os.path.join(test_imgs_dir, img_name),num_primary_color)
    # # Create a DataFrame to store the color palettes
    # palette_df = pd.DataFrame()
    # # Append the color palette to the DataFrame
    manual_colors = []
    # for i in range(0, len(center), 3):
    #   manual_colors.append([center[i], center[i + 1], center[i + 2]])

    series = []
    for dominant_color in dominant_colors:
        manual_colors.append([dominant_color["red"], dominant_color["green"], dominant_color["blue"]])
        series.append(dominant_color["red"])
        series.append(dominant_color["green"])
        series.append(dominant_color["blue"])

    choose_colors_max = len(manual_colors)
    print("Max: ", choose_colors_max)



    manual_colors = np.array(manual_colors) / 255.0
    #
    #
    #
    # palette_df = palette_df.append(pd.Series([math.floor(i) for i in center]), ignore_index=True)
    # palette_df = palette_df.append(pd.Series([math.floor(i) for i in center]), ignore_index=True)
    # palette_df = palette_df.append(pd.Series(series), ignore_index=True)
    # palette_df = pd.concat([palette_df, pd.Series(series)], ignore_index=True)
    # palette_df = pd.concat([palette_df, pd.Series(series)], ignore_index=True)
    # # Save the DataFrame to a CSV file
    # palette_df.to_csv(pallete_csv_path, index=False, header=False)
    with open(pallete_csv_path, mode="w") as pallete_file:
        line = ",".join(map(str, series))
        pallete_file.write(line + "\n" + line)

    # Create Output Dir
    create_dir_if_not_exists(pathlib.Path(processing_dir, "results", run_name, final_img_name))
    create_dir_if_not_exists(pathlib.Path(processing_dir, "results", run_name, final_img_name, "layers"))
    # path_mask_generator = f'{processing_dir}/models' + '/mask_generator.pth'
    # path_residue_predictor = f'{processing_dir}/models' + '/residue_predictor.pth'

    test_dataset = MyDataset(csv_path, pallete_csv_path, choose_colors_max, mode='test')
    test_loader = torch.utils.data.DataLoader(
        test_dataset,
        batch_size=1,
        shuffle=False,
        num_workers=0,
    )

    # # define model
    global mask_generator, residue_predictor
    mask_generator = MaskGenerator(choose_colors_max).to(device)
    residue_predictor = ResiduePredictor(choose_colors_max).to(device)
    #
    # # load params
    # #   %pwd
    mask_generator.load_state_dict(torch.load(path_mask_generator, map_location=device))
    residue_predictor.load_state_dict(torch.load(path_residue_predictor, map_location=device))
    #
    # # eval mode
    mask_generator.eval()
    residue_predictor.eval()

    generate_layers(run_name, final_img_name, test_loader, manual_colors)

    psd_path = generate_psd(original_img_name)
    return psd_path
